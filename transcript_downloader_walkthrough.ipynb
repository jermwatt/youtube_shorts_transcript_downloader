{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/jermwatt/youtube_transcript_downloader/blob/main/transcript_downloader_walkthrough.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# if running in collab pull repo and install requirements\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "    !git clone https://github.com/jermwatt/youtube_transcript_downloader.git\n",
    "    %cd youtube_transcript_downloader\n",
    "    !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Youtube transcript downloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem:\n",
    "- this expert youtuber [has downloaded THOUSANDS of transcripts BY HAND](https://youtu.be/As7abwNhG7Y?si=dSzEf6Hk0glROYhu&t=340) to analyze them\n",
    "- oy say 10 secs per video copy/paste, for 1000 videos that's 10000 secs / 167 mins minimum of copying and pasting just the transcripts\n",
    "- let's help anyone else in the future who wants to do this save a bunch of time\n",
    "\n",
    "Let's build:\n",
    "- a simple app you can run locally that lets you\n",
    "- upload a .txt file with youtube urls, extracts their transcripts and\n",
    "- once complete lets you download a .csv or .xlsx file with the transcripts nicely organized by url / video id\n",
    "\n",
    "Tool's we'll need:\n",
    "- [youtube_transcript_api](https://github.com/jdepoix/youtube-transcript-api) - a simple python api using the requests library and the YouTube web-client\n",
    "- [streamlit](https://github.com/streamlit/streamlit) for the app framework (components, web UI, etc.,)\n",
    "- custom code to organize data, batch process, create and organize output, etc.,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Pulling transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we'll create simple wrappers on [youtube_transcript_api](https://github.com/jdepoix/youtube-transcript-api) to pull transcripts \n",
    "- built in batch mode &#x1f929; - so we can pull multiple video transcripts at once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- simple functionality below \n",
    "    - `is_valid_youtube_url` type checks input youtube urls to ensure they are formatted correctly\n",
    "    - `get_single_transcript` pulls the transcript of a single video\n",
    "    - `get_batch_transcripts` pulls transcripts of multiple input videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List, Dict\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "\n",
    "def is_valid_youtube_url(potential_url: str) -> bool:\n",
    "    pattern = r'^https://www\\.youtube\\.com/watch\\?v=[A-Za-z0-9_-]{11}$'  # youtube ids are always 11 chars long\n",
    "    return re.match(pattern, potential_url) is not None\n",
    "    \n",
    "def get_single_transcript(youtube_url: str) -> dict:\n",
    "    try:\n",
    "        if is_valid_youtube_url(youtube_url):\n",
    "            video_id = youtube_url.split(\"?v=\")[-1]\n",
    "            video_transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "            entry = {}\n",
    "            entry[\"youtube_url\"] = youtube_url\n",
    "            entry[\"video_id\"] = video_id\n",
    "            entry[\"transcript\"] = video_transcript\n",
    "            return entry\n",
    "        else:\n",
    "            print(f\"FAILURE: youtube_url is not valid - {youtube_url}\")\n",
    "            return {}\n",
    "    except Exception as e:\n",
    "        print(f\"FAILURE: transcript pull for youtube_url - {youtube_url} - failed with exception {e}\")\n",
    "        return {}\n",
    "\n",
    "def get_batch_transcripts(youtube_urls: List[str]) -> List[Dict]:\n",
    "    valid_urls = []\n",
    "    valid_vids = []\n",
    "    for i, url in enumerate(youtube_urls):\n",
    "        if is_valid_youtube_url(url):\n",
    "            vid = url.split(\"?v=\")[-1]\n",
    "            valid_urls.append(url)\n",
    "            valid_vids.append(vid)\n",
    "    try:\n",
    "        video_transcripts = YouTubeTranscriptApi.get_transcripts(valid_vids, languages=[\"en\"])\n",
    "        entries = []\n",
    "        for i in range(len(valid_urls)):\n",
    "                entry = {}\n",
    "                entry[\"youtube_url\"] = valid_urls[i]\n",
    "                entry[\"video_id\"] = valid_vids[i]\n",
    "                entry[\"transcript\"] = video_transcripts[i]\n",
    "                entries.append(entry)\n",
    "        return entries\n",
    "    except Exception as e:\n",
    "        print(f\"FAILURE: batch transcription fetch failed with exception {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test our functionality with two videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test transcript pull functionality with two test videos\n",
    "youtube_url_1 = \"https://www.youtube.com/watch?v=As7abwNhG7Y\"\n",
    "youtube_url_2 = \"https://www.youtube.com/watch?v=0TolBiTrUg4\"\n",
    "youtube_urls = [youtube_url_1, youtube_url_2]\n",
    "single_transcript = get_single_transcript(youtube_url_1)\n",
    "batch_transcripts = get_batch_transcripts(youtube_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'youtube_url': 'https://www.youtube.com/watch?v=As7abwNhG7Y', 'video_id': 'As7abwNhG7Y', 'transcript': [{'text': \"I don't ask if it'll go viral I can\", 'start': 0.04, 'duration': 3.399}, {'text': 'figure out how to make it viral that is', 'start': 1.599, 'duration': 4.361}, {'text': 'an absurd thing to', 'start': 3.439, 'duration': 5.921}, {'text': \"say that's Jenny Hoyos an 18-year-old\", 'start'\n"
     ]
    }
   ],
   "source": [
    "# print the first few hundred characters of return object\n",
    "print(str(single_transcript)[:400])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Input and output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- lets design and build two helper functions for I/O\n",
    "- input will be a text file with one youtube url per line - `parse_input_file` implements this\n",
    "- output will be a csv file - `save_output` implements this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def parse_input_file(input_file_path: str) -> list:\n",
    "    youtube_urls = []\n",
    "    with open(input_file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            youtube_urls.append(line.strip())\n",
    "    return youtube_urls\n",
    "\n",
    "\n",
    "def save_output(data: list,\n",
    "                output_file_path: str) -> None:\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
